# **금융 시계열 데이터 파이프라인을 위한 서버리스 아키텍처: DynamoDB, Lambda, S3, Valkey Cache를 활용한 고빈도 데이터 집계 및 실시간 배포 전략**

## **1\. 서론: 현대 금융 데이터 아키텍처의 요구사항과 과제**

금융 거래 데이터의 처리는 데이터 엔지니어링 분야에서 가장 까다로운 요구사항을 가진 영역 중 하나입니다. 거래(Trade)라는 원시 데이터는 예측 불가능한 속도로 발생하며, 이는 시장의 변동성에 따라 초당 수천 건에서 수십만 건에 이르는 버스트(Burst) 트래픽을 유발합니다. 이러한 고빈도 데이터를 실시간으로 수집하여 사용자에게 1분, 5분, 1시간, 1일, 1달 등 다양한 시간 프레임의 캔들(OHLCV: Open, High, Low, Close, Volume) 차트 데이터로 가공하여 제공하는 시스템은 극도의 낮은 지연 시간(Low Latency)과 데이터 무결성(Data Integrity), 그리고 비용 효율성을 동시에 만족해야 합니다.

본 보고서에서는 AWS의 관리형 서비스인 DynamoDB, Lambda, S3, EventBridge와 고성능 인메모리 데이터 스토어인 Valkey(Redis의 오픈 소스 포크)를 결합하여, 거래 데이터의 수집부터 캔들 생성, 저장, 그리고 웹소켓을 통한 실시간 배포에 이르는 엔드투엔드(End-to-End) 아키텍처를 심층적으로 분석하고 제안합니다. 특히 거래가 발생하지 않는 구간에서도 차트의 연속성을 보장해야 하는 '시간 대 틱(Time vs. Tick)'의 딜레마를 해결하기 위한 EventBridge 기반의 봉 마감 트리거 아키텍처와, 대용량 데이터의 효율적인 관리를 위한 계층적 스토리지 전략을 중점적으로 다룹니다.1

서버리스 컴퓨팅 모델은 유휴 자원에 대한 비용을 제거하고 트래픽에 따라 자동 확장이 가능하다는 장점이 있으나, 상태 관리(State Management)의 어려움과 콜드 스타트(Cold Start)로 인한 지연 시간 문제가 존재합니다. 이를 보완하기 위해 Valkey Cache를 'Hot' 계층으로 도입하여 실시간 집계의 상태를 관리하고, DynamoDB를 'Warm' 계층으로 사용하여 데이터의 영속성을 보장하며, S3를 'Cold' 계층으로 활용하여 장기 보관 및 분석 비용을 최적화하는 3계층 데이터 수명 주기 전략을 제시합니다.2 본 문서는 이러한 기술적 선택의 근거와 구체적인 구현 알고리즘을 상세히 기술하여, 금융 IT 전문가들이 실제 프로덕션 환경에 적용 가능한 수준의 청사진을 제공하는 것을 목적으로 합니다.

## **2\. 데이터 수집 및 영속성 계층: DynamoDB 스키마 설계와 트레이드 레저**

거래 데이터의 유입은 모든 파이프라인의 시작점이며, 이 데이터의 손실은 곧 금전적 손실로 이어질 수 있습니다. 따라서 원시 거래 데이터(Raw Trades)는 발생 즉시 내구성이 보장되는 저장소에 기록되어야 합니다. DynamoDB는 이러한 요구사항에 부합하는 밀리초 단위의 쓰기 성능과 무제한 확장성을 제공합니다.

### **2.1 거래 내역 저장을 위한 DynamoDB 파티셔닝 전략**

DynamoDB의 성능은 파티션 키(Partition Key)의 설계에 전적으로 의존합니다. 거래 데이터와 같이 시계열 특성을 가지면서도 특정 종목(Symbol)에 트래픽이 집중될 수 있는 데이터의 경우, 단순한 Symbol 파티셔닝은 '핫 파티션(Hot Partition)' 문제를 야기할 수 있습니다. 예를 들어, 특정 호재로 인해 비트코인(BTC)의 거래량이 폭증할 경우, 해당 파티션에만 쓰기 요청이 몰려 스로틀링(Throttling)이 발생할 수 있습니다.4

이를 해결하기 위해 본 아키텍처에서는 시간 기반의 접미사를 포함한 복합 파티션 키 전략을 제안합니다.

| 속성명 | 데이터 타입 | 설명 | 예시 값 |
| :---- | :---- | :---- | :---- |
| PK | String | 파티션 키. SYMBOL\#YYYY-MM-DD-HH 형식을 사용하여 시간별로 파티션을 분산. | BTC/USDT\#2025-12-14-10 |
| SK | String | 정렬 키. TIMESTAMP\#TRADE\_ID 형식을 사용하여 시간 순 정렬 및 고유성 보장. | 1702512000123\#998877 |
| p | Number | 거래 가격 (Price) | 42000.50 |
| q | Number | 거래 수량 (Quantity) | 0.5 |
| s | String | 매매 구분 (Side: 'buy' 또는 'sell') | buy |
| TTL | Number | 데이터 만료 시간 (Unix Timestamp). | 1702598400 (24시간 후) |

이러한 설계는 다음과 같은 이점을 제공합니다. 첫째, 파티션 키에 시간을 포함함으로써 단일 파티션에 데이터가 무한정 쌓이는 것을 방지하고, 쓰기 용량을 시간대별로 분산시킬 수 있습니다.6 둘째, 정렬 키를 통해 특정 시간 범위의 거래 내역을 효율적으로 조회(Query 연산)할 수 있어, 장애 발생 시 캔들 데이터를 재생성(Replay)하거나 감사(Audit) 목적으로 활용하기 용이합니다.

### **2.2 핫/콜드 데이터 분리를 위한 TTL 활용**

DynamoDB는 고성능 스토리지이므로 저장 비용이 상대적으로 높습니다. 모든 거래 내역을 영구적으로 DynamoDB에 보관하는 것은 비효율적입니다. 따라서 TTL(Time-To-Live) 기능을 활용하여 생성 후 24시간이 지난 원시 거래 데이터는 자동으로 삭제되도록 설정합니다.1 영구 보관이 필요한 데이터는 DynamoDB 스트림이나 별도의 Kinesis Firehose 파이프라인을 통해 S3로 적재하는 이중화 전략을 사용합니다. 이는 운영 데이터베이스의 크기를 일정하게 유지하여 쿼리 성능을 보장하고 비용을 절감하는 핵심 전략입니다.

## ---

**3\. 실시간 집계 엔진: Valkey Cache 활용 알고리즘**

사용자가 보는 차트의 가장 오른쪽, 즉 현재 생성 중인 캔들(Active Candle)은 매 거래가 발생할 때마다 실시간으로 업데이트되어야 합니다. DynamoDB는 강력하지만, 초당 수천 번의 업데이트가 발생하는 단일 레코드(현재 1분 봉)에 대해 매번 쓰기 연산을 수행하는 것은 비용과 지연 시간 측면에서 비효율적입니다. 여기서 Valkey(Redis)가 인메모리 버퍼 역할을 수행하며 극도로 낮은 지연 시간을 제공합니다.1

### **3.1 Valkey 데이터 구조 설계**

Valkey에서는 각 종목의 각 시간 프레임(1분, 5분 등)에 대해 '활성 캔들' 상태를 유지해야 합니다. 단순한 Key-Value 구조보다는 해시(Hash) 구조를 사용하여 필드별 업데이트를 최적화하는 것이 유리합니다.

**Key 형식:** candle:active:{timeframe}:{symbol} (예: candle:active:1m:BTC/USDT)

**Hash 필드 구성:**

* o (Open): 시가. 캔들 생성 시점에만 설정.  
* h (High): 고가. 현재가와 비교하여 더 높을 때만 업데이트.  
* l (Low): 저가. 현재가와 비교하여 더 낮을 때만 업데이트.  
* c (Close): 종가. 매 거래마다 현재가로 업데이트.  
* v (Volume): 거래량. 매 거래마다 누적 가산(HINCRBYFLOAT).  
* q (Quote Volume): 거래대금. 매 거래마다 가격 \* 수량을 누적 가산.  
* t (Open Time): 캔들 시작 시간.

### **3.2 Lua 스크립트를 이용한 원자적 업데이트 알고리즘**

동시성 제어는 금융 데이터에서 매우 중요합니다. 여러 거래가 동시에 들어올 때, 읽기-수정-쓰기(Read-Modify-Write) 패턴을 애플리케이션 레벨에서 수행하면 경쟁 조건(Race Condition)으로 인해 고가나 저가가 잘못 기록될 수 있습니다. Valkey는 단일 스레드로 동작하며 Lua 스크립트 실행의 원자성(Atomicity)을 보장하므로, 복잡한 비교 및 갱신 로직을 서버 측 스크립트로 처리하는 것이 가장 안전합니다.3

**실시간 처리 알고리즘 (Lua Script):**

1. **입력:** 거래 가격(price), 거래 수량(quantity), 거래 시간(timestamp), 캔들 주기(interval).  
2. **시간 계산:** 거래 시간을 기준으로 현재 캔들의 시작 시간(open\_time)을 계산합니다. (open\_time \= timestamp \- (timestamp % interval))  
3. **키 조회:** 해당 Key가 존재하는지 확인합니다.  
4. **분기 처리:**  
   * **신규 생성 (Key 없음):** HMSET을 사용하여 시가, 고가, 저가, 종가를 모두 현재 price로 설정하고, 거래량을 quantity로 초기화합니다. 만료 시간(EXPIRE)을 설정하여 데이터가 영구히 남는 것을 방지합니다.  
   * **갱신 (Key 존재):**  
     * 현재 저장된 h(고가)와 l(저가)을 가져옵니다.  
     * 입력 price가 h보다 크면 h를 업데이트합니다.  
     * 입력 price가 l보다 작으면 l을 업데이트합니다.  
     * c(종가)를 무조건 price로 업데이트합니다.  
     * v(거래량)에 quantity를 더합니다.  
5. **반환:** 갱신된 전체 캔들 데이터(OHLCV)를 반환하여 웹소켓 배포에 사용합니다.

이 알고리즘은 람다 함수나 별도의 컨슈머가 Valkey에 요청을 보낼 때 단 한 번의 네트워크 왕복(RTT)만으로 모든 갱신 로직을 안전하게 처리할 수 있게 해줍니다.

## ---

**4\. 봉 마감 트리거 아키텍처: EventBridge와 람다의 오케스트레이션**

가장 기술적으로 난이도가 높은 부분은 캔들의 '마감(Closing)' 처리입니다. 1분 봉은 매분 59초에서 00초로 넘어가는 순간 확정되어야 합니다. 그러나 거래 데이터에만 의존하여 캔들을 마감하려고 하면, 거래가 발생하지 않는 시간대에는 캔들이 생성되지 않거나 마감 로직이 실행되지 않는 문제가 발생합니다. 이를 해결하기 위해 '시간 기반(Time-Based)' 트리거가 필수적입니다.

### **4.1 EventBridge Scheduler 기반의 크론 아키텍처**

Amazon EventBridge Scheduler를 사용하여 매분 정각(cron(0 \* \* \*? \*))에 CandleCloserFn 람다 함수를 트리거합니다. 이 방식은 거래량과 무관하게 시스템이 주기적으로 상태를 점검하고 데이터를 확정할 수 있게 해줍니다.1

**트리거 흐름:**

1. **EventBridge:** 매분 0초에 이벤트를 발행합니다.  
2. **Dispatcher Lambda:** 이 람다는 Valkey에서 '현재 활성화된 종목 목록(active:symbols)'을 조회합니다. 수천 개의 종목을 단일 람다에서 처리하면 타임아웃이 발생할 수 있으므로, 종목 리스트를 50\~100개 단위로 분할(Sharding)하여 SQS 큐에 넣거나 여러 개의 워커(Worker) 람다를 비동기로 호출합니다.8  
3. **Worker Lambda (CandleCloserFn):** 할당된 종목들에 대해 실제 마감 로직을 수행합니다.

### **4.2 갭 필링(Gap Filling)과 데이터 정합성**

워커 람다가 수행하는 핵심 로직은 다음과 같습니다.

1. **Valkey 조회:** candle:active:1m:{symbol} 키를 조회하여 지난 1분간의 누적 데이터를 가져옵니다.  
2. **데이터 존재 시:**  
   * 해당 데이터를 DynamoDB의 CandleHistory 테이블에 저장합니다.  
   * S3 저장을 위해 Kinesis Firehose로 데이터를 전송합니다.  
   * Valkey에서 해당 키를 삭제하거나 다음 분을 위한 초기 상태로 리셋합니다.  
3. **데이터 미존재 시 (거래 없음):**  
   * 금융 차트에서는 거래가 없더라도 캔들이 끊기지 않고 이어져야 합니다(이전 종가를 유지).  
   * Valkey 또는 DynamoDB에서 '직전 봉의 종가(Previous Close)'를 조회합니다.  
   * 시가=고가=저가=종가=직전 종가, 거래량=0 인 'Doji' 캔들을 생성하여 DynamoDB에 저장합니다.  
   * 이 과정을 통해 차트의 시간축 연속성을 보장합니다.

이 아키텍처는 거래 데이터의 유입(Data Driven)과 시간의 흐름(Time Driven)을 분리함으로써, 시장 상황에 관계없이 안정적인 데이터 파이프라인을 유지할 수 있게 합니다.

## ---

**5\. 재귀적 롤업(Recursive Roll-up) 전략: 1분에서 1달까지**

1분 봉 데이터가 확정되면, 이를 기반으로 상위 시간 프레임(5분, 15분, 1시간, 4시간, 1일, 1주, 1달)의 캔들을 생성해야 합니다. 원시 거래 데이터를 다시 집계하는 것은 막대한 컴퓨팅 자원을 낭비하는 것이므로, 하위 캔들을 재집계하는 '재귀적 롤업' 방식을 사용합니다.1

### **5.1 계층적 집계 알고리즘**

각 상위 시간 프레임은 하위 시간 프레임의 정수배로 구성됩니다.

* **5분 봉:** 5개의 1분 봉 집계.  
* **1시간 봉:** 60개의 1분 봉 또는 12개의 5분 봉 집계.  
* **1일 봉:** 24개의 1시간 봉 집계.

**집계 로직:**

* **Open:** 첫 번째 하위 캔들의 Open.  
* **High:** 모든 하위 캔들의 High 중 최댓값.  
* **Low:** 모든 하위 캔들의 Low 중 최솟값.  
* **Close:** 마지막 하위 캔들의 Close.  
* **Volume:** 모든 하위 캔들의 Volume 합계.

### **5.2 이벤트 기반 연쇄 트리거 (Cascading Trigger)**

모든 시간 프레임에 대해 별도의 크론 잡을 돌리는 것은 동기화 문제를 야기합니다. 대신, 하위 봉의 마감 이벤트가 상위 봉의 갱신을 트리거하는 방식을 제안합니다.

1. CandleCloserFn이 1분 봉을 마감하고 DynamoDB에 저장한 후, EventBridge로 CandleClosed 이벤트를 발행합니다(페이로드: {symbol: "BTC", timeframe: "1m", time: 10:05}).  
2. EventBridge 규칙(Rule)이 이 이벤트를 감지합니다.  
   * 규칙 조건: timeframe \== '1m' AND minute % 5 \== 0\.  
   * 이 조건이 충족되면 RollupFn 람다를 호출하여 5분 봉을 생성합니다.  
3. RollupFn은 5분 봉을 생성하고 다시 CandleClosed 이벤트(timeframe: "5m")를 발행합니다.  
4. 또 다른 규칙이 이를 감지하여 timeframe \== '5m' AND minute \== 0 일 때 1시간 봉을 생성합니다.

이러한 연쇄적 패턴(Chained Pattern)은 불필요한 폴링을 제거하고, 데이터가 준비된 시점에 즉시 상위 집계가 수행되도록 보장합니다.10 또한, 1달 봉과 같이 캘린더 기준(매월 1일)으로 변동하는 주기는 별도의 스케줄러를 통해 1일 봉 데이터를 집계하는 방식으로 유연하게 처리할 수 있습니다.

## ---

**6\. 스토리지 계층화 및 S3 아카이빙 전략**

데이터가 오래될수록 접근 빈도는 낮아지지만 분석을 위한 대량 스캔의 필요성은 높아집니다. DynamoDB는 단건 조회에는 최적화되어 있으나 대량 분석용으로는 비용 효율이 낮습니다. 따라서 S3를 활용한 콜드 스토리지 전략이 필수적입니다.

### **6.1 Kinesis Firehose를 이용한 Parquet 변환**

캔들 데이터가 DynamoDB에 저장되는 시점에 Kinesis Data Firehose로도 동일한 데이터를 전송합니다. Firehose는 데이터를 버퍼링(예: 5분 또는 128MB)한 후 S3로 적재합니다. 이때 중요한 것은 데이터 포맷입니다. JSON 대신 **Apache Parquet**와 같은 컬럼 기반(Columnar) 포맷으로 변환하여 저장해야 합니다.1

Parquet 포맷은 높은 압축률을 제공하여 S3 저장 비용을 절감할 뿐만 아니라, 이후 S3 Select나 Athena를 사용하여 쿼리할 때 필요한 컬럼만 스캔할 수 있어 조회 성능과 비용 효율성을 극대화합니다.11

### **6.2 S3 파티셔닝 구조 설계**

S3에 저장된 데이터의 조회 성능은 파티셔닝 구조에 의해 결정됩니다. 금융 데이터의 조회 패턴은 주로 "특정 종목의 특정 기간"입니다. 따라서 다음과 같은 하이브(Hive) 스타일 파티셔닝 구조를 권장합니다.13

s3://bucket-name/candles/timeframe={TF}/symbol={SYM}/year={YYYY}/month={MM}/day={DD}/data.parquet

이 구조를 사용하면 Athena나 S3 Select 쿼리 시 WHERE symbol='BTC' AND year='2025'와 같은 조건절을 통해 스캔해야 할 파일의 범위를 획기적으로 줄일(Partition Pruning) 수 있습니다. 1분 봉 데이터의 경우 일(Day) 단위 파티셔닝이 적절하며, 데이터 양이 적은 월봉이나 주봉은 연(Year) 단위 파티셔닝으로 충분할 수 있습니다.

## ---

**7\. API 제공 및 웹소켓 실시간 배포**

사용자에게 데이터를 전달하는 계층은 REST API(과거 데이터 조회)와 WebSocket(실시간 업데이트)으로 구성됩니다.

### **7.1 하이브리드 조회 API (Lambda)**

GetCandles API는 요청된 시간 범위에 따라 DynamoDB(Hot)와 S3(Cold)를 지능적으로 라우팅해야 합니다.1

* **Logic:**  
  * 요청: Symbol=BTC, Range=최근 3일 \-\> DynamoDB 쿼리 (빠른 응답).  
  * 요청: Symbol=BTC, Range=작년 1달간 \-\> S3 Select 쿼리 (비용 효율적).  
  * 요청: Symbol=BTC, Range=최근 1년 \-\> S3 Select로 과거 데이터를 가져오고, DynamoDB에서 최근 데이터를 가져와 람다에서 병합(Stitching).

이 방식은 사용자에게 단일 엔드포인트를 제공하면서도 백엔드에서는 비용과 성능의 균형을 자동으로 맞출 수 있습니다.

### **7.2 웹소켓 아키텍처와 팬아웃(Fan-out)**

수만 명의 클라이언트에게 실시간으로 틱 데이터를 전송하는 것은 높은 처리량을 요구합니다. API Gateway WebSocket API를 사용하되, 메시지 브로드캐스팅을 위한 팬아웃 전략이 필요합니다.

1. **Valkey Pub/Sub 활용:** 실시간 집계 엔진(Lua Script)이 캔들 업데이트를 완료하면, 변경된 데이터를 Valkey의 채널(pub:candle:1m:BTC)에 발행(Publish)합니다.15  
2. **Broadcaster:** 별도의 람다 함수나 장기 실행 컨테이너(Fargate)가 이 채널을 구독(Subscribe)하고 있습니다.  
3. **Connection 관리:** 클라이언트가 웹소켓에 접속하면 connectionId와 구독 정보를 Valkey의 Set 자료구조(subs:BTC)에 저장합니다.  
4. **전송:** Broadcaster는 Pub/Sub 메시지를 수신하면, 해당 종목을 구독 중인 모든 connectionId를 Valkey에서 조회하여 API Gateway의 @connections 엔드포인트를 통해 데이터를 병렬 전송합니다.17

Valkey Streams를 사용할 수도 있으나, 실시간 가격 정보는 '소실되어도 다음 틱에 복구되는' 특성이 있어 Pub/Sub 모델의 'Fire-and-Forget' 방식이 지연 시간 측면에서 더 유리할 수 있습니다.16 단, 메시지 순서가 중요한 경우 Streams 도입을 고려해야 합니다.

## ---

**8\. 결론 및 제언**

본 보고서에서 제안한 아키텍처는 AWS의 서버리스 생태계와 Valkey의 고성능 캐싱을 결합하여 금융 데이터 시스템의 난제를 해결합니다. DynamoDB는 쓰기 집약적인 워크로드를 안정적으로 처리하고, Valkey는 실시간성을 보장하며, S3와 Parquet은 장기적인 비용 효율성을 제공합니다. EventBridge를 활용한 마감 트리거와 재귀적 롤업 전략은 시스템의 복잡도를 낮추면서도 데이터의 정합성을 보장하는 핵심 메커니즘입니다.

이 아키텍처를 도입함으로써 기업은 인프라 관리의 부담 없이 시장 변동성에 유연하게 대처할 수 있으며, 사용자에게는 제도권 금융 수준의 신뢰성 높은 차트 데이터를 제공할 수 있을 것입니다. 향후 시스템 확장 시에는 람다 함수의 실행 시간을 단축하기 위해 Rust나 Go 언어를 도입하거나, 웹소켓 연결 관리를 위해 전용 EC2 클러스터를 도입하는 하이브리드 접근 방식도 고려해볼 수 있습니다.